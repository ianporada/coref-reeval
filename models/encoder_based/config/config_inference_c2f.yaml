seed: 0
output_dir: '$SCRATCH/kd-coref-project-output'
cache_dir: '$SCRATCH/cache/datasets_cache'

preprocessing_cfg:
  cache_dir: ${cache_dir}
  tokenizer_name: microsoft/deberta-large
  tokenizer_type: not-t5
  genres: {"bc": 0, "bn": 1, "mz": 2, "nw": 3, "pt": 4, "tc": 5, "wb": 6}
  max_segment_len: 512
  max_training_segments: 11
  
model_ckpt: /network/scratch/x/xiyuan.zou/kd-coref-project-output/lightning_logs/version_111/checkpoints/epoch=23-step=67248.ckpt
dataset_name: ontoGUM #support ontonotes, GAP and ontoGUM
dataset_split: train
use_official_scorer: False
inference_device: gpu #A100-large by default